{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Descentes de Gradient\n",
    "\n",
    "Ce TP vise à apporter les éléments nécessaires pour comprendre les implementations des descentes de gradients. **C'est un *TP à trous* ; il s'agira de compléter ces trous et d'y ajouter les tests qui vous sembleront utiles.**\n",
    "\n",
    "Voici un aperçu des points abordés lors de ce TP.\n",
    "\n",
    "- partie I\n",
    "    - Définition d'un ensemble de fonctions test\n",
    "- partie II\n",
    "    - Calcul du gradient d'une fonction de manière approchée (pour couvrir des cas où le calcul explicite du gradient est impossible ou pénible).\n",
    "    \n",
    "**Première Partie: Les méthodes de descente \"classiques\" pour une fonction différentiable**\n",
    "\n",
    "- partie I\n",
    "    - La descente dans la direction du Gradient à pas constant\n",
    "    - Optimisation du pas par Backtracking\n",
    "- partie II\n",
    "    - Choix d'une autre direction que le gradient\n",
    "        - De plus forte pente en norme $l_1$\n",
    "        - Gradient conjugué\n",
    "- partie III\n",
    "    - La Méthode de Newton et la méthode de quasi-Newton\n",
    "- partie IV\n",
    "    - visualisation graphique des itérés succesifs\n",
    "    - comparaison des méthodes\n",
    "    \n",
    "Dans l'ensemble du déroulé du TP vous ferez bien attention à valider par un jeu de tests la validité des programmes écrits. Vous regarderez l'influence des paramètres sur la convergence. Vous comparerez les intérêts des diférentes méthodes les unes par rapport aux autres ... Et vous vous prendrez les précautions nécessaires pour éviter les boucles infinies !!!\n",
    "\n",
    "**Votre démarche et vos conclusions seront présentées sous forme d'un rapport (de 10 à 15 pages) où vous pourrez choisir d'avoir une approche plus sur les résultats mathématiques ou sur les résultats numériques. Le notebook Jupiter avec l'ensemble de vos travaux sera aussi remis.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attendus de rendu\n",
    "\n",
    "Votre rendu sera jugé à l'aune de\n",
    "\n",
    "- votre capacité à produire des algorithmes valides, répondant à la question posée\n",
    "- l'étude effectuée concernant la sensibilité de vos algorithmes aux hyperparamètres / conditions initiales\n",
    "- l'analyse comparative proposée quant aux différentes implémentations suggérées \n",
    "- les stress-tests auxquels vous aurez confrontés vos implémentations.\n",
    "- Il sera particulièrement apprécié la validation numérique des résultats théoriques présentés en cours sur la convergence ou divergence des méthodes, sur leur vitesse de convergence ...\n",
    "\n",
    "On portera une attention particulière à la *généricité* de votre réponse ; tout comme cela vous est suggéré par la suite on attendra de vous d'appuyer vos affirmations par suffisamment de tests et une appréciation pour les limites de votre analyse.\n",
    "\n",
    "Ce TP est à rendre par **groupes de 3** et exceptionnellement **2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Au travail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I- Un set de fonctions tests\n",
    "\n",
    "Dans cette partie nous allons introduire quelques fonctions test qui nous permettront de représenter les situations suivantes:\n",
    "- Fonctions globalement convexes ou uniquement localement convexes\n",
    "- Fonctions admettant ou non un minimum global\n",
    "- Fonctions admettant ou non des minimums locaux\n",
    "\n",
    "Nous partons de fonctions définies sur $\\mathbb{R}$ mais on verra que cela permet de définir des fonctions \"intéressantes\" sur $\\mathbb{R}^n$.\n",
    "\n",
    "On verra aussi comment calculer le gradient de manière approchée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions du set de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. La banane de Rosenbrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Voici une fonction célèbre pour tester les algorithmes d'optimisation.\n",
    "\n",
    "$$f(x,y)=(x-1)^2+\\gamma (x^2-y)^2$$.\n",
    "\n",
    "Ce n'est pas évident à visualiser mais cette fonction présente un minimum global unique qui se situe au fond d'une vallée très étroite et en forme de parabole.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rosenbrock(x,gamma=5):\n",
    "        return (x[0]-1)**2+gamma*(x[0]**2-x[1])**2 #valeur de la fonction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -1.1, 1.2, -0.5, 2\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=Rosenbrock(np.array([X[i,j],Y[i,j]]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "\n",
    "ax.contour(X, Y, Z,200) \n",
    "  \n",
    "ax.set_title('fonction Rosenbrock') \n",
    "ax.set_xlabel('x') \n",
    "ax.set_ylabel('y') \n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "cmap='jet', edgecolor='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Une fonction cubique  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic1_(x,gamma):\n",
    "        return x**3 + gamma*x**2 + x + 1 #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "x = np.linspace(-10, 10, 400)\n",
    "ax.set_ylim(-50, 150)\n",
    "for gamma in range(0, 11, 1):\n",
    "    ax.plot(x, cubic1_(x, gamma), label=\"gamma: {}\".format(gamma))\n",
    "ax.set_title(\"Famille cubique en dimension 1\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic2_(x,gamma=10):\n",
    "        return cubic1_(x[0],gamma)+cubic1_(x[1],gamma) #valeur de la fonction ou de son grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -10, 5, -10, 5\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=cubic2_(np.array([X[i,j],Y[i,j]]))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "\n",
    "ax.contour(X, Y, Z,50) \n",
    "  \n",
    "ax.set_title('fonction cubic2') \n",
    "ax.set_xlabel('x') \n",
    "ax.set_ylabel('y') \n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. On construit ici une fonction convexe en dimension n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On va prendre comme fonction test la fonction convexe \"générique\" dans $\\mathbb{R}^n$, $ x \\mapsto \\frac{1}{2}x^T A x-b^Tx$, \n",
    "\n",
    "où A est une matrice symétrique définie positive de taille $(n,n)$ et $b$ un vecteur de $\\mathbb{R}^n$.\n",
    "\n",
    "On a vu en cours que cette fonction est convexe, qu'elle admet donc un minimum global sur $\\mathbb{R}^n$, et que ce minimum est atteint au point où son gradient s'annule, c'est à dire au point où $Ax=b$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Une manière commode de construire une matrice $A$ symétrique définie positive est de la voir comme une matrice de la forme $A=U^T U$ avec $U$ triangulaire supérieure car cela nous permet  à la fois de s'assurer qu'elle est symétrique, inversible, positive et en plus de \"contrôler\" les valeurs propres de $A$ et donc son conditionnement.\n",
    "Le conditionnement de $A$ est le rapport entre la plus grande et la plus petite de ses valeurs propres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system (dim,cond=10,seed=100):\n",
    "    np.random.seed(seed)\n",
    "    U=np.random.uniform(-math.sqrt(cond),math.sqrt(cond),size=(dim,dim))/dim\n",
    "    U=np.triu(U,1)\n",
    "    # on remplace la diagonale de U par des valeurs aléatoires positives entre 1 et sqrt(cond)\n",
    "    U=U+np.diag(np.random.uniform(1.,math.sqrt(cond),size=(dim))) \n",
    "    # on impose les deux premiers termes de la diagonale diagonale de A pour fixer le conditionnement\n",
    "    U[0,0]=1.\n",
    "    U[1,1]=math.sqrt(cond)\n",
    "    b=1.*np.random.randint(-10,10,size=(dim))\n",
    "    A=U.T @ U\n",
    "    return A,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,b = create_system(10,cond=10)\n",
    "print (A,b)\n",
    "val,vec = np.linalg.eig(A)\n",
    "print (val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadraticn_(x):\n",
    "        return (x.T@A@x)/2-b.T@x #valeur de la fonction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -20, 10, -10, 10\n",
    "\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "dim=2\n",
    "A,b = create_system(dim,cond=10)\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=quadraticn_(np.array([X[i,j],Y[i,j]]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "\n",
    "ax.contour(X, Y, Z,15) \n",
    "  \n",
    "ax.set_title('quadraticn_') \n",
    "ax.set_xlabel('x') \n",
    "ax.set_ylabel('y') \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On voit sur ces quelques exemples que des fonctions d'apparence \"inoffensives\" peuvent avoir des comportements complexes en ce qui concerne leurs extrema locaux ou globaux.\n",
    "\n",
    "${\\bf Nous \\, vous \\, invitons \\, à \\, tester \\, vos \\, programmes}$\n",
    "* sur la fonction quadratique pour la dimension n=2 puis n=10, et pour des conditionnements variant de 5 à 1000.\n",
    "* sur la fonction de Rosenbrock pour des valeurs de gamma variant de 5 à 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## II- Différencier une fonction numériquement\n",
    "\n",
    "Pour calculer le gradient d'une fonction on a déjà besoin de savoir calculer la dérivée d'une fonction réelle, et on en tire ensuite une version numérique du gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le calcul numérique de la dérivée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pour $h$ assez petit on peut approcher $f'(x)$ par \n",
    "$$ f'(x) \\simeq \\frac{f(x + h) - f(x)}{h} .$$\n",
    "L'erreur de l'approximation est en $o(1)$ quand $h \\to 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ $$\n",
    "On peut en réalité faire un peu mieux en approchant $f'(x)$ par \n",
    "$$f'(x) \\simeq \\frac{f(x+h)-f(x-h)}{2h}$$.\n",
    "On trouve que l'erreur d'approximation dans le second cas est désormais en $o(h)$ quand $h \\to 0$; ce qui est a priori meilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Utiliser la démarche précédente pour approcher la dérivée partielle d'une fonction en un point. Cette fonction sera notée `partial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial(f, x, i=0, dx=1e-8):\n",
    "    \"\"\"Computes i-th partial derivative of f at point x.\n",
    "    \n",
    "    Args:\n",
    "        f: objective function.\n",
    "        x: point at which partial derivative is computed.\n",
    "        i: coordinate along which derivative is computed.\n",
    "        dx: slack for finite difference.\n",
    "        \n",
    "    Output:\n",
    "        (float)\n",
    "\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Comparer `partial` à l'expression exacte de la dérivée partielle d'une fonction de votre choix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le calcul du gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dit précédemment, comme le calcul exact du gradient n'est parfois pas possible ou facile, on se garde la possibilité de calculer numériquement le gradient d'une fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Écrire une fonction `gradient` qui renvoie le gradient d'une fonction en un point grâce à la fonction précédente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(f, x, dx=1e-5):\n",
    "    \"\"\"Computes gradient of f at point x.\n",
    "    \n",
    "    Args:\n",
    "        f: objective function.\n",
    "        x: point at which gradient is computed.\n",
    "        dx: slack for finite difference of partial derivatives.\n",
    "        \n",
    "    Output:\n",
    "        (ndarray) of size domain of f.\n",
    "        \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tester cette fonction gradient sur une fonction connue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PARTIE I- Les méthodes de descente \"classiques\" pour une fonction différentiable\n",
    "\n",
    "Cette partie représente la première partie du TP est devrait être bien entamée lors de la première séance de TP et achevée (y compris la partie \"rapport\") avant la deuxième séance de TP. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## I- Descente du gradient\n",
    "\n",
    "Tout d'abord, nous allons implémenter des descentes qui se feront dans la direction du Gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### le cas générique de descente de gradient avec un pas constant\n",
    "\n",
    "\n",
    "* prendre un point de départ au hasard ${\\bf p_0}$.\n",
    "\n",
    "Quand on est au point ${\\bf p_k}$\n",
    "\n",
    "* calculer le gradient de J en ce point $\\nabla J({\\bf p_k})$\n",
    "\n",
    "* On choisit une direction de descente ${\\bf d}_k = - \\nabla J({\\bf p}_k)$\n",
    "\n",
    "* avancer dans cette direction : ${\\bf p}_{k+1} = {\\bf p}_k + \\mu \\, {\\bf d}_k$\n",
    "\n",
    "et on recommence cette dernière étape jusqu'à ce qu'on arrive à un point fixe c.a.d. que \n",
    "$|| {\\bf p}_{k+1} - {\\bf p}_k|| < \\varepsilon$ avec $\\varepsilon$ une toute petite valeur.\n",
    "\n",
    "Implémenter cette méthode, la tester sur des fonctions tests définies plus haute, observer en particulier le comportement en fonction de $\\mu$ qui est le pas constant.\n",
    "\n",
    "Attention: bien prévoir dans le code des conditions pour éviter de se retrouver piégé dans des boucles infinies !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Implémenter cette méthode, la tester sur des fonctions tests définies plus haute, observer en particulier le comportement en fonction de $\\mu$ qui est le pas constant.\n",
    "\n",
    "Attention: bien prévoir dans le code des conditions pour éviter de se retrouvé piégé dans des boucles infinies !!!\n",
    "On conseille de stocker les différentes valeurs calculées pour les points ${\\bf p_k}$ afin de pouvoir \"regarder\" la manière dont la convergence se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_grad_const (f,p0,mu=0.001,eps=1E-6):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "    Parameters:\n",
    "    p0: point initial\n",
    "    f: fonction à minimiser\n",
    "    mu: valeur \n",
    "    \n",
    "    Output\n",
    "    liste comportant l'ensemble des pk\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=10\n",
    "cond=100.\n",
    "A,b = create_system(dim,cond)\n",
    "x_exact=np.zeros(dim)+1.\n",
    "b=A@x_exact\n",
    "\n",
    "x0=np.zeros(dim)\n",
    "res = desc_grad_const(quadraticn_,x0,mu=0.01)\n",
    "\n",
    "print (\"Nb itérations\",len(res))\n",
    "print(\"x_calculé\",res[-1])\n",
    "print (\"x_exact\",x_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1ère amélioration: le choix d'un pas \"optimal\" à chaque étape par *backtracking* (ou rebroussement avec critère d'Armijo)\n",
    "\n",
    "Vous devriez avoir constatés que le choix du pas de descente dans le cas constant est crucial pour garantir la convergence de l'algorithme de descente. Dans cette section on s'intéresse à un calcul adaptatif du pas de descente qui permet de mieux garantir la convergence de notre algo. Le désavantage est le temps que prend désormais chaque itération pour s'exécuter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on veut imposer la décroissance de la suite $J({\\bf p}_k)$ ce qui nous assurera la convergence. Mais pour assurer la convergence vers un minimum, il faut imposer un peu plus que simplement de descendre, c'est ce que traduit le critère d'Armijo.\n",
    "\n",
    "On prend ici deux paramètres $0<\\alpha<0.5$ et $0<\\beta<1$.\n",
    "\n",
    "On cherche un $\\mu$ qui vérifie:\n",
    "$$ J({\\bf p}_k+\\mu d_k) < J({\\bf p}_k) + \\alpha \\, \\mu \\, d_k ^T \\, \\nabla J({\\bf p}_k)\\quad (1).$$\n",
    "\n",
    "On a vu en cours q'un tel $\\mu$ existe dès que $d_k$ est une direction de descente (c'est à dire dès que $d_k ^T \\, \\nabla J({\\bf p}_k) \\, <\\, 0$.\n",
    "\n",
    "* On part de $\\mu = 1$\n",
    "\n",
    "* si la condition $(1)$ ci-dessus est vérifiée on choisit cette valeur de $\\mu$\n",
    "\n",
    "* sinon on change $\\mu$ en $\\beta \\, \\mu$\n",
    "\n",
    "Et on recommence jusqu'à ce que la condition $(1)$ soit vérifiée.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Écrire une fonction `backtracking` qui permet de calculer le pas par *backtracking* avec critère d'Armijo à une itération donnée. Pour rappel le *backtracking* a deux hyper-paramètre $\\alpha$ et $\\beta$ que vous mettrez par défaut à $0.4$ et $0.8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction génère la taille du pas optimal vérifiant le critère d'Amijo\n",
    "\n",
    "def backtrack(x0, f , dir_x, alpha = 0.4, beta = 0.8):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "    Parameters:\n",
    "    x0: point actuel\n",
    "    f: fonction à minimiser\n",
    "    dir_x: direction dans laquelle on souhaite aller\n",
    "    \n",
    "    Output\n",
    "    valeur du pas choisi\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode est donc très analogue à la précédente\n",
    "\n",
    "* prendre un point de départ au hasard ${\\bf p_0}$.\n",
    "\n",
    "Quand on est au point ${\\bf p_k}$\n",
    "\n",
    "* Calculer le gradient de J en ce point $\\nabla J({\\bf p_k})$\n",
    "\n",
    "* Choisir une direction de descente ${\\bf d}_k = - \\nabla J({\\bf p}_k)$\n",
    "\n",
    "* Trouver $\\mu_k$ par \"backtracking\" dans la direction ${\\bf d}_k$\n",
    "\n",
    "* Avancer dans cette direction et avec ce pas : ${\\bf p}_{k+1} = {\\bf p}_k + \\mu \\, {\\bf d}_k$\n",
    "\n",
    "et on recommence ces étapes jusqu'à ce qu'on arrive à un point fixe c.a.d. que \n",
    "$|| {\\bf p}_{k+1} - {\\bf p}_k|| < \\varepsilon$ avec $\\varepsilon$ une toute petite valeur.\n",
    "\n",
    "#### 2. Implémenter cette méthode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_grad_opti (f,p0,eps=1E-6):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tester cette descente sur des cas simples (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Comparer la descente par backtracking et la descente à pas constant (à vous de réfléchir à ce que vous voulez comparer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## II- Changement de direction de descente\n",
    "\n",
    "Maintenant nous ne nous déplacerons plus nécessairement dans la direction de $-\\nabla J({\\bf p_k})$ mais dans une autre direction $d_k$ qui vérifiera bien évidemment $\\langle \\nabla J({\\bf p_k}) , d_k \\rangle < 0$ afin que ce soit bien une direction de descente (et non de montée !!!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Choisir une direction de descente selon la plus forte pente en norme $l_1$\n",
    "\n",
    "Nous allons ici choisir la descente de plus forte pente dans le cas de la norme $\\ell_1$ : la direction de descente $d_k$ suit le vecteur de la base canonique de plus grande dérivée partielle en valeur absolue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ {\\bf d}_k = -\\langle \\nabla J({\\bf p}_k),e_i \\rangle \\, e_i$$\n",
    "où $i$ est le plus petit indice tel que:\n",
    "$ \\left| \\dfrac{\\partial J}{\\partial x_i}({\\bf p}_k) \\right| = \\|\\nabla J({\\bf p}_k)\\|_{\\infty}  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Écrire une fonction `dsgd` qui calcule cette direction de descente de plus forte pente dans le cas de la norme $\\ell_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsgd(f, x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: \n",
    "    Parameters:\n",
    "    x: point actuel\n",
    "    f: fonction à minimiser\n",
    "    \n",
    "    Output\n",
    "    vecteur de direction de descente de gradient maximal en norme l1\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Ecrire la descente à pas optimal avec cette direction de descente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\bf p}_{k+1} = {\\bf p}_k + \\mu_k {\\bf d}_k$, où $\\mu_k$ est calculé de manière optimale par l'algorithme de rebroussement avec critère d'Amijo défini plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_l1 (f, p0, eps=1E-6):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Comparer la descente $\\ell_1$ et la descente du gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. le gradient conjugué (Fletcher-Reeves)\n",
    "\n",
    "Dans la méthode du gradient conjugué, on modifie la direction de descente en ajoutant à l'opposé du gradient un terme dépendant des directions de descente précédentes. Ce choix de descente est fait pour rendre deux directions de descentes orthogonales pour le produit scalaire qui vient de la Hessienne.\n",
    "\n",
    "Ce calcul (qui est direct quand la fonctionnelle est quadratique) peut devenir compliqué quand la Hessienne n'est pas directement accessible.\n",
    "\n",
    "Une des méthodes les plus populaires pour une fonctionnelle quelconque est celle proposée par Fletcher-Reeves. Nous vous invitons à faire un peu de bibliographie (ou vos notes de cours) pour trouver comment la direction est choisie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse: $d_{k+1}=$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Ecrire la descente à pas optimal avec cette direction de descente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_FR (f, p0, eps=1E-6):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. le gradient conjugué (Polack-Ribière)\n",
    "\n",
    "Une méthode alternative est celle proposée par Polack-Ribière. Nous vous invitons à faire un peu de bibliographie (ou vos notes de cours) pour trouver comment la direction est choisie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse: Réponse: $d_{k+1}=$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Ecrire la descente à pas optimal avec cette direction de descente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_PR (f, p0, eps=1E-6):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - \"Les\" méthodes de Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. la méthode de Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les méthodes de descente précédentes, on cherchait à chaque étape à minimiser le Développement Limité d'ordre 1 de J au voisinage de ${\\bf p_k}$: $h \\mapsto J({\\bf p_k}) + \\nabla J({\\bf p_k}) ^T h$.\n",
    "\n",
    "Dans la méthode de Newton, on cherche à minimiser le Développement Limité d'ordre 2 de J au voisinage de ${\\bf p}_k$ : $h \\mapsto J({\\bf p}_k) + \\nabla J({\\bf p}_k) ^T h + \\dfrac{1}{2}h^T H_J({\\bf p}_k) h$ où $H_J({\\bf p}_k)$ est la Hessienne de J au point ${\\bf p}_k$.\n",
    "\n",
    "A quelle direction de descente, cette minimisation nous amène-t-elle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse:\n",
    "\n",
    "\n",
    "On passe de la direction ${\\bf d}_k$ à la direction ${\\bf d}_{k+1}$ par la relation de récurrence:\n",
    "$${\\bf d}_{k+1}=-H_J({\\bf p}_k)^{-1} \\, \\nabla J({\\bf p}_k) .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Implémenter la méthode de Newton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En apparence, implémenter la méthode de Newton (qui converge très rapidement) ne semble pas différent que les méthodes de descente vues précédemment (Une fois qu'on a obtenu ${\\bf d}_k$ comme direction de descente, on peut calculer $\\mu_k$ et donc itérer \"tranquillement).\n",
    "\n",
    "En réalité cette méthode n'est pas facile à implémenter et surtout coûteuse car il faut calculer à chaque itération la Hessienne de $J$ au point ${\\bf p}_k)$ et ensuite l'inverser.\n",
    "\n",
    "Vous pouvez essayer de l'implémenter dans le cas particulier de la fonction quadraticn_ car alors la matrice Hessienne est constante et ne dépend donc pas du point ${\\bf p}_k)$, ce qui vous permet de calculer une fois pour toute son inverse (par le module linalg de numpy par exemple).\n",
    "\n",
    "Par contre implémenter cette méthode dans le cas d'une fonction dont on ne connaît pas explicitement la Hessienne, et surtout l'inverse de cette dernière est à déconseiller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Facultatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. la méthode de quasi-Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter les inconvénients de la méthode de Newton, en particulier lorsque la Hessienne n'est plus constante, une idée est d'introduire une suite de matrices $H_k$ qui sont une approximation de $\\bf {l'inverse}$ de la Hessienne au point ${\\bf p}_k$.\n",
    "\n",
    "Cette méthode qui s'appelle méthode BFGS (des initiales des auteurs) qui l'ont introduite, a l'avantage (énorme) de ne pas nécessiter le calcul de la Hessienne ou de son inverse. on retrouve donc en terme d'implémentation la simplicité des méthodes de descente, tout en ayant les propriétés de convergence de la méthode de Newton.\n",
    "\n",
    "Nous vous invitons à faire un peu de bibliographie ou de revoir vos notes de cours pour trouver la manère de construire cette suite $H_k$\n",
    "\n",
    "La méthode est donc très analogue à la précédente\n",
    "\n",
    "* prendre un point de départ quelconque ${\\bf p}_0$, par exemple ${\\bf p}_0 = ${\\bf 0}$\n",
    "* prendre une matrice $H_0$ quelconque, par exemple $H_0= I_n$ \n",
    "\n",
    "Quand on est au point ${\\bf p}_k$\n",
    "\n",
    "* Choisir une direction de descente ${\\bf d}_k = -H_k \\, \\nabla J({\\bf p}_k)$\n",
    "\n",
    "* Trouver $\\mu_k$ par \"backtracking\" dans la direction ${\\bf d}_k$\n",
    "\n",
    "* Avancer dans cette direction et avec ce pas : ${\\bf p}_{k+1} = {\\bf p}_k + \\mu \\, {\\bf d}_k$\n",
    "\n",
    "* Calculer $H_{k+1}$ en fonction de $H_k$, $J({\\bf p}_k)$, $J({\\bf p}_{k+1})$, $\\nabla J({\\bf p}_k)$ et $\\nabla J({\\bf p}_{k+1})$.\n",
    "\n",
    "et on recommence ces étapes jusqu'à ce qu'on arrive à un point fixe c.a.d. que \n",
    "$|| {\\bf p}_{k+1} - {\\bf p}_k|| < \\varepsilon$ avec $\\varepsilon$ une toute petite valeur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire un petit peu de biblio pour trouver comment se calcule la suite des matrices $H_{k+1}$. La formule qui semble à première vue horrible, se programme en Python en 1 ligne en ne faisant que des multiplications de matrices et de vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse:\n",
    "Si on note ${\\bf s}_k = {\\bf p}_{k+1} - {\\bf p}_k$ et ${\\bf y}_k = \\nabla J({\\bf p}_{k+1}) - \\nabla J({\\bf p}_k)$.\n",
    "\n",
    "On a alors:\n",
    "$$ H_{k+1}=$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Implémenter la méthode de Quasi-Newton BFGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_BFGS (f, p0, eps=1E-6):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Comparer la méthode de quasi-Newton aux descentes précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. visualiser et comparer les différents algorithmes de descente et leur sensibilité par rapport au conditionnement\n",
    "\n",
    "Nous vous proposons de visualiser le comportement de ces différents algorithmes de descente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. visualiser de la manière dont les points se rapprochent du minimum\n",
    "\n",
    "Tout d'abord en dimension 2, vous pouvez tracer la succession des points $p_k$ pour les algorithmes implémentés en les superposant les courbes de niveau de la fonctionnelle.\n",
    "Vous pourrez le faire pour la fonction quadratique et pour la banane de Rosenbrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=2\n",
    "A,b = create_system(dim,cond=3.)\n",
    "x_exact=np.zeros(dim)+1.\n",
    "b=A@x_exact\n",
    "\n",
    "x0=np.zeros(dim)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "Liste_method=(desc_grad_const,desc_grad_opti,desc_l1,desc_FR,desc_PR,desc_BFGS)\n",
    "\n",
    "for method in Liste_method:\n",
    "\n",
    "    if method == desc_grad_const:\n",
    "        res = method(quadraticn_,x0,mu=0.9/cond)\n",
    "    else:\n",
    "        res = method(quadraticn_,x0)\n",
    "\n",
    "    plt.plot(res[:,0], res[:,1],label=method)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -0.1, 1.5, -0.1, 1.4\n",
    "\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=quadraticn_(np.array([X[i,j],Y[i,j]]))\n",
    "        \n",
    "        \n",
    "plt.contour(X, Y, Z,25) \n",
    "\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Idem pour la banane de Rosenbrock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualiser la vitesse de convergence des différents algorithmes de descente et leur sensibilité par rapport au conditionnement\n",
    "\n",
    "En dimension n plus grande (par exemple n=10), vous pourrez tracer le nombre d'itérations nécessaires pour converger en fonction du conditionnement (5,10,50,100,500,1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dim=10\n",
    "\n",
    "Liste_cond=(2,5,10,20,50,100,200, 500,1000)\n",
    "Liste_method=(desc_grad_const,desc_grad_opti,desc_l1,desc_FR,desc_PR,desc_BFGS)\n",
    "iter=np.zeros(len(Liste_cond))\n",
    "\n",
    "for method in Liste_method:\n",
    "    k=0\n",
    "    for cond in Liste_cond:\n",
    "        A,b = create_system(dim,cond)\n",
    "        x_exact=np.zeros(dim)+1.\n",
    "        b=A@x_exact\n",
    "        x0=np.zeros(dim)\n",
    "    \n",
    "        if method == desc_grad_const:\n",
    "            res = method(quadraticn_,x0,mu=0.9/cond)\n",
    "        else:\n",
    "            res = method(quadraticn_,x0)\n",
    "    \n",
    "        iter[k]=len(res)\n",
    "    \n",
    "        k=k+1\n",
    "    \n",
    "    plt.plot(Liste_cond[:], iter[:],label=method)\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez aussi regarder pour une certaine valeur de conditionnement, comment varie la distance à la solution exacte en fonction de l'itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=10\n",
    "cond=1000\n",
    "Liste_method=(desc_grad_const,desc_grad_opti,desc_l1,desc_FR,desc_PR,desc_BFGS)\n",
    "\n",
    "A,b = create_system(dim,cond)\n",
    "x_exact=np.zeros(dim)+1.\n",
    "b=A@x_exact\n",
    "x0=np.zeros(dim)\n",
    "\n",
    "l=0\n",
    "for method in Liste_method:\n",
    "    if method == desc_grad_const:\n",
    "        res = method(quadraticn_,x0,mu=0.9/cond)\n",
    "    else:\n",
    "        res = method(quadraticn_,x0)\n",
    "    \n",
    "    xx=np.zeros(len(res))\n",
    "    yy=np.zeros(len(res))\n",
    "    \n",
    "    for i in range(len(res)):\n",
    "        xx[i]=i\n",
    "        yy[i]=np.sqrt((res[i]-x_exact)@(res[i]-x_exact))\n",
    "    \n",
    "    plt.plot(xx,yy**0.5,label=method)\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"erreur\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    l=l+1\n",
    "    plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
